{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ec4152b-8b6a-4c84-acb5-400d80a5ea96",
   "metadata": {},
   "source": [
    "# Setting Up GPU / CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd548e29-f59f-44ad-a953-cf01800e87d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7827beb-11db-4294-bda0-6ab6c1cb4b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Activate GPU for faster training by clicking on 'Runtime' > 'Change runtime type' and then selecting GPU as the Hardware accelerator\n",
    "# Then check if GPU is available\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "020c7ff4-80b0-4437-93ac-1ba65c156bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Setting up the device for GPU usage\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047d3b15-e49a-4cdb-b037-7236adce12cf",
   "metadata": {},
   "source": [
    "# Installing and Loading Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9d13fe-7f93-4b9c-872c-dd02c99b89bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install transformers torch pandas numpy datasets accelerate scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1456f56e-32ab-431e-bbd8-dbdf1f7a3188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, Trainer, TrainerCallback, TrainingArguments\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ce72659-966c-4d00-9022-6d08511b29ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25cd3def-c3ef-4bb2-abb5-9c4175c70db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b0894f8-16d7-4476-8d51-203bb955188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc2e364-7d85-4947-9813-5c8fca7f5031",
   "metadata": {},
   "source": [
    "# Importing The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1106cc96-5250-41af-ae9c-9084a876d8f6",
   "metadata": {},
   "source": [
    "## Bitext - Customer Service Tagged Training Dataset\n",
    "\n",
    "### Overview\n",
    "\n",
    "This dataset can be used to train intent recognition models on Natural Language Understanding (NLU) platforms: LUIS, Dialogflow, Lex, RASA and any other NLU platform that accepts text as input.\n",
    "\n",
    "The training dataset contains 8,100 utterances (300 per intent), because most platforms limit the number of utterances that can be used for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574584a7-e74d-42d3-b43e-c0b1cc8624b4",
   "metadata": {},
   "source": [
    "## Cleaning up the dataset\n",
    "\n",
    "From the dataset, we are removing the categories which is not having less than 3 intents, which removes the following categories:\n",
    "- CANCELLATION_FEE\n",
    "- FEEDBACK\n",
    "- NEWSLETTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e60def6-8a80-4b8f-aedd-46e25129a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#navigate to parent directory\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "#setting the filenames\n",
    "training_file = os.path.join(parent_dir, 'data/train/Bitext_Sample_Customer_Service_Training_Dataset.csv')\n",
    "testing_file  = os.path.join(parent_dir, 'data/test/Bitext_Sample_Customer_Service_Testing_Dataset.csv')\n",
    "\n",
    "#opening the files\n",
    "training_df = pd.read_csv(training_file)\n",
    "testing_df  = pd.read_csv(testing_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9183b7bc-dc9e-4d2d-89e5-2b3fae3dfa10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>intent</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>entity_value</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>category</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how can I cancel purchase 113542617735902?</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>order_id</td>\n",
       "      <td>113542617735902</td>\n",
       "      <td>26.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>BIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>can you help me canceling purchase 00004587345?</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>order_id</td>\n",
       "      <td>00004587345</td>\n",
       "      <td>35.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>BIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i want assistance to cancel purchase 732201349959</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>order_id</td>\n",
       "      <td>732201349959</td>\n",
       "      <td>37.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>BLQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i want assistance to cancel order 732201349959</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>order_id</td>\n",
       "      <td>732201349959</td>\n",
       "      <td>34.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>BQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I don't want my last item, help me cancel orde...</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>order_id</td>\n",
       "      <td>370795561790</td>\n",
       "      <td>48.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>BCLN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           utterance        intent  \\\n",
       "0         how can I cancel purchase 113542617735902?  cancel_order   \n",
       "1    can you help me canceling purchase 00004587345?  cancel_order   \n",
       "2  i want assistance to cancel purchase 732201349959  cancel_order   \n",
       "3     i want assistance to cancel order 732201349959  cancel_order   \n",
       "4  I don't want my last item, help me cancel orde...  cancel_order   \n",
       "\n",
       "  entity_type     entity_value  start_offset  end_offset category  tags  \n",
       "0    order_id  113542617735902          26.0        41.0    ORDER   BIL  \n",
       "1    order_id      00004587345          35.0        46.0    ORDER   BIL  \n",
       "2    order_id     732201349959          37.0        49.0    ORDER   BLQ  \n",
       "3    order_id     732201349959          34.0        46.0    ORDER    BQ  \n",
       "4    order_id     370795561790          48.0        60.0    ORDER  BCLN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d840d2ce-09e8-46e3-962c-42113b37ecf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>intent</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>entity_value</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>category</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I do not know how I can cancel purchase 00123842</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>order_id</td>\n",
       "      <td>00123842</td>\n",
       "      <td>40.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>BEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>help to cancel purchase 00004587345</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>order_id</td>\n",
       "      <td>00004587345</td>\n",
       "      <td>24.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>BL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cancelling purchase 00123842</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>order_id</td>\n",
       "      <td>00123842</td>\n",
       "      <td>20.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>BKL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cancel purchase 00004587345</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>order_id</td>\n",
       "      <td>00004587345</td>\n",
       "      <td>16.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>BKL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I  don't know how to cancel order 732201349959</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>order_id</td>\n",
       "      <td>732201349959</td>\n",
       "      <td>34.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>BZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          utterance        intent entity_type  \\\n",
       "0  I do not know how I can cancel purchase 00123842  cancel_order    order_id   \n",
       "1               help to cancel purchase 00004587345  cancel_order    order_id   \n",
       "2                      cancelling purchase 00123842  cancel_order    order_id   \n",
       "3                       cancel purchase 00004587345  cancel_order    order_id   \n",
       "4    I  don't know how to cancel order 732201349959  cancel_order    order_id   \n",
       "\n",
       "   entity_value  start_offset  end_offset category tags  \n",
       "0      00123842          40.0        48.0    ORDER  BEL  \n",
       "1   00004587345          24.0        35.0    ORDER   BL  \n",
       "2      00123842          20.0        28.0    ORDER  BKL  \n",
       "3   00004587345          16.0        27.0    ORDER  BKL  \n",
       "4  732201349959          34.0        46.0    ORDER   BZ  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56434e11-9afe-4f1f-bfec-8be619a27c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retain only categories with intents more than 2\n",
    "training_df = training_df[training_df[\"category\"].isin(['ACCOUNT', 'CONTACT', 'ORDER', 'PAYMENT', 'REFUND', 'SHIPPING_ADDRESS'])]\n",
    "# retain only categories with intents more than 2\n",
    "testing_df = testing_df[testing_df[\"category\"].isin(['ACCOUNT', 'CONTACT', 'ORDER', 'PAYMENT', 'REFUND', 'SHIPPING_ADDRESS'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3571c0c0-e3b6-4442-a496-48ba6acd3f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_preprocess(input_df):\n",
    "    # drop other columns\n",
    "    # keep only utterance, intent and tags\n",
    "    df = input_df[['utterance','intent', 'tags']]\n",
    "\n",
    "    df['encoded_intent'] = df['intent'].astype('category').cat.codes\n",
    "    df['labels'] = df['tags'].apply(lambda x: [1 if letter in x else 0 for letter in 'QPWKBCIMLEZ'])\n",
    "\n",
    "    columns_to_drop = ['intent', 'tags']\n",
    "    new_df = df.drop(columns_to_drop, axis=1)\n",
    "    # new_df.head()\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b9b7af-ce4f-4f80-8e86-7651bddbf84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset_preprocess(training_df)\n",
    "test_data  = dataset_preprocess(testing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58bf3b1a-d9c1-430e-9cc3-01666aecaeee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>encoded_intent</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how can I cancel purchase 113542617735902?</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>can you help me canceling purchase 00004587345?</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i want assistance to cancel purchase 732201349959</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i want assistance to cancel order 732201349959</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I don't want my last item, help me cancel orde...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           utterance  encoded_intent  \\\n",
       "0         how can I cancel purchase 113542617735902?               0   \n",
       "1    can you help me canceling purchase 00004587345?               0   \n",
       "2  i want assistance to cancel purchase 732201349959               0   \n",
       "3     i want assistance to cancel order 732201349959               0   \n",
       "4  I don't want my last item, help me cancel orde...               0   \n",
       "\n",
       "                              labels  \n",
       "0  [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]  \n",
       "1  [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]  \n",
       "2  [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0]  \n",
       "3  [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]  \n",
       "4  [0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "943d375a-a46a-4007-8707-47984722351c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>encoded_intent</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I do not know how I can cancel purchase 00123842</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>help to cancel purchase 00004587345</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cancelling purchase 00123842</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cancel purchase 00004587345</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I  don't know how to cancel order 732201349959</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          utterance  encoded_intent  \\\n",
       "0  I do not know how I can cancel purchase 00123842               0   \n",
       "1               help to cancel purchase 00004587345               0   \n",
       "2                      cancelling purchase 00123842               0   \n",
       "3                       cancel purchase 00004587345               0   \n",
       "4    I  don't know how to cancel order 732201349959               0   \n",
       "\n",
       "                              labels  \n",
       "0  [0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0]  \n",
       "1  [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0]  \n",
       "2  [0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0]  \n",
       "3  [0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0]  \n",
       "4  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d102396c-7e63-4ce8-940d-ee2b50fcc48e",
   "metadata": {},
   "source": [
    "# PreProcessing and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4275cdf-6a69-4725-a510-075858bd8d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set DistilBERT tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f7d62308-e00d-4154-a4c8-8d5851d27a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the text inputs for the model\n",
    "def preprocess_function(examples):\n",
    "\n",
    "    intent_labels = np.zeros(19)\n",
    "\n",
    "    # assigning the labels for intents\n",
    "    for i in range(len(intent_labels)):\n",
    "      intent_value = examples[\"encoded_intent\"]\n",
    "      intent_labels[intent_value] = 1\n",
    "\n",
    "    # tags labels\n",
    "    tags = np.array(examples[\"labels\"])\n",
    "\n",
    "    labels = np.append(intent_labels, tags)\n",
    "\n",
    "    examples = tokenizer(examples[\"utterance\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "    examples[\"label\"] = labels\n",
    "\n",
    "    # print(len(examples[\"label\"]))\n",
    "\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8b7dfb25-0acb-4520-b059-77257cd49ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2215, 5375, 2000, 17542, 2344, 6421, 19317, 24096, 22022, 2683, 2683, 28154, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.])}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the preprocess_function\n",
    "preprocess_function({\n",
    "    \"utterance\": \"i want assistance to cancel order 732201349959\",\n",
    "    \"encoded_intent\": 0,\n",
    "    \"labels\": [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d961e399-c57f-4216-bc0e-165cc7869b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Dataset: (4580, 3)\n",
      "TEST Dataset: (565, 3)\n"
     ]
    }
   ],
   "source": [
    "# Creating the dataset and dataloader for the neural network\n",
    "\n",
    "print(\"TRAIN Dataset: {}\".format(train_data.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_data.shape))\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "test_dataset = Dataset.from_pandas(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dcd18f84-7751-4427-80ab-64db6d0e387c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████| 4580/4580 [00:00<00:00, 6460.40 examples/s]\n",
      "Map: 100%|███████████████████████| 565/565 [00:00<00:00, 6628.15 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the text inputs for the model\n",
    "\n",
    "tokenized_train = train_dataset.map(preprocess_function)\n",
    "tokenized_test = test_dataset.map(preprocess_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a91a2d-5a65-4dba-a8e0-05a496405481",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "988ac74e-eafe-48ec-8f3e-b88d5047cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the training parameters\n",
    "\n",
    "LEARNING_RATE = 1e-05\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 10\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1d9339c0-135d-4f9e-a0ac-82dbe1d140e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use data_collector to convert our samples to PyTorch tensors and concatenate them with the correct amount of padding\n",
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4f8e6cff-2479-4463-85bf-c6e2417d078c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=30, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define DistilBERT as our base model:\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=30) #total output features = 19+11 = 30\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54718969-fbbb-4ae5-a021-f64a69b570c9",
   "metadata": {},
   "source": [
    "## OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1603d372-a541-4cc8-9e09-c4e6577cfbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install torch_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1daf4204-5754-4029-8ec3-d917f821979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_optimizer as optim\n",
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d5015351-809a-419e-8d2f-c5d7e8870e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d346bef-e8a3-4ada-b130-0ee0f923e5f1",
   "metadata": {},
   "source": [
    "# Prepare the Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f04ecd8-ca9b-4852-b498-114906bd3c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "INTENT_INDICES = range(0,19)\n",
    "TAGS_INDICES   = range(19,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b7e113fc-d722-4169-857b-65c1fed47ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply two logics for Multiclass Columns and Multilabel Columns\n",
    "def get_preds_from_logits(logits):\n",
    "    ret = np.zeros(logits.shape)\n",
    "\n",
    "    # The first 19 columns are for customer intents. They should be handled with a multiclass approach\n",
    "    # i.e. we fill 1 to the class with highest probability, and 0 into the other columns\n",
    "    best_class = np.argmax(logits[:, INTENT_INDICES], axis=-1)\n",
    "    ret[list(range(len(ret))), best_class] = 1\n",
    "\n",
    "    # The other columns are for register tags. They should be handled with multilabel approach.\n",
    "    # i.e. we fill 1 to every class whose score is higher than some threshold\n",
    "    # In this example, we choose that threshold = 0\n",
    "    ret[:, TAGS_INDICES] = (logits[:, TAGS_INDICES] >= 0).astype(int)\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0c8c62bd-7fde-4562-a0fd-ec91c05dbe22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.50183952,  1.80285723,  0.92797577,  0.39463394, -1.37592544,\n",
       "        -1.37602192, -1.76766555,  1.46470458,  0.40446005,  0.83229031,\n",
       "        -1.91766202,  1.87963941,  1.32977056, -1.15064356, -1.27270013,\n",
       "        -1.26638196, -0.78303103,  0.09902573, -0.27221993, -0.83508344,\n",
       "         0.44741158, -1.44202456, -0.83142141, -0.53455263, -0.17572006,\n",
       "         1.14070385, -1.20130487,  0.05693775,  0.36965828, -1.81419835]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let’s look at an example by generating a random 30-dimensional vector whose columns are between -2 and 2\n",
    "example = np.random.uniform(-2, 2, (1, 30))\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5d900390-cf5a-4cdc-844a-f946af188dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0.])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the predicted vector\n",
    "get_preds_from_logits(example)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c16afa7c-eae9-4833-b946-6652ccea3b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    final_metrics = {}\n",
    "\n",
    "    # Deduce predictions from logits\n",
    "    predictions = get_preds_from_logits(logits)\n",
    "\n",
    "    # Get f1 metrics for global scoring. Notice that f1_micro = accuracy\n",
    "    final_metrics[\"f1_micro_for_intents\"] = f1_score(labels[:, INTENT_INDICES], predictions[:, INTENT_INDICES], average=\"micro\")\n",
    "    final_metrics[\"f1_macro_for_intents\"] = f1_score(labels[:, INTENT_INDICES], predictions[:, INTENT_INDICES], average=\"macro\")\n",
    "\n",
    "    # Get f1 metrics for causes\n",
    "    final_metrics[\"f1_micro_for_tags\"] = f1_score(labels[:, TAGS_INDICES], predictions[:, TAGS_INDICES], average=\"micro\")\n",
    "    final_metrics[\"f1_macro_for_tags\"] = f1_score(labels[:, TAGS_INDICES], predictions[:, TAGS_INDICES], average=\"macro\")\n",
    "\n",
    "    # The global f1_metrics\n",
    "    final_metrics[\"f1_micro\"] = f1_score(labels, predictions, average=\"micro\")\n",
    "    final_metrics[\"f1_macro\"] = f1_score(labels, predictions, average=\"macro\")\n",
    "\n",
    "    # Classification report\n",
    "    print(\"Classification report for intents: \")\n",
    "    print(classification_report(labels[:, INTENT_INDICES], predictions[:, INTENT_INDICES], zero_division=0))\n",
    "    print(\"Classification report for tags: \")\n",
    "    print(classification_report(labels[:, TAGS_INDICES], predictions[:, TAGS_INDICES], zero_division=0))\n",
    "\n",
    "    return final_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897fe7fe-b783-4935-92ac-7849359f5a86",
   "metadata": {},
   "source": [
    "# LOSS FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5af0cc7a-6974-4cbe-b2f8-33bd9d9b088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskClassificationTrainer(Trainer):\n",
    "    def __init__(self, group_weights=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.group_weights = group_weights\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs[0]\n",
    "\n",
    "        intent_loss = torch.nn.functional.cross_entropy(logits[:, INTENT_INDICES], labels[:, INTENT_INDICES])\n",
    "        tags_loss = torch.nn.functional.binary_cross_entropy_with_logits(logits[:, TAGS_INDICES], labels[:, TAGS_INDICES])\n",
    "\n",
    "        loss = self.group_weights[0] * intent_loss + self.group_weights[1] * tags_loss\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fa9fa4f1-55cb-4fd3-891e-e22533421e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print epoch number at each step\n",
    "class PrinterCallback(TrainerCallback):\n",
    "    def on_epoch_end(self, args, state, control, logs=None, **kwargs):\n",
    "        print(f\"Epoch {state.epoch}: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c231e0-32cc-4120-954a-a3f0277abe05",
   "metadata": {},
   "source": [
    "# TRAINER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b738434f-f79c-4093-8f54-7ed6f677bd56",
   "metadata": {},
   "source": [
    "### Accelerator Workaround"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "954bd661-99c4-404d-8e16-cccca4d99158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('4.31.0', '0.21.0')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import accelerate\n",
    "import transformers\n",
    "\n",
    "transformers.__version__, accelerate.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "dced01ab-58bb-4b1c-a06d-55cc39fc2eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new Trainer with all the objects we constructed so far\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./models/\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    load_best_model_at_end=True,\n",
    "    weight_decay=0.01,\n",
    "    optim='adamw_torch',\n",
    ")\n",
    "\n",
    "trainer = MultiTaskClassificationTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[PrinterCallback],\n",
    "    data_collator=data_collator,\n",
    "    group_weights=(0.8, 2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3be032cd-0761-414a-a97d-7800eb6bc03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11450' max='11450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11450/11450 16:09, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Micro For Intents</th>\n",
       "      <th>F1 Macro For Intents</th>\n",
       "      <th>F1 Micro For Tags</th>\n",
       "      <th>F1 Macro For Tags</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.545300</td>\n",
       "      <td>0.442694</td>\n",
       "      <td>0.991150</td>\n",
       "      <td>0.990726</td>\n",
       "      <td>0.865390</td>\n",
       "      <td>0.528233</td>\n",
       "      <td>0.896796</td>\n",
       "      <td>0.821145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.327000</td>\n",
       "      <td>0.274998</td>\n",
       "      <td>0.992920</td>\n",
       "      <td>0.992236</td>\n",
       "      <td>0.919195</td>\n",
       "      <td>0.739265</td>\n",
       "      <td>0.937084</td>\n",
       "      <td>0.899480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.217800</td>\n",
       "      <td>0.200191</td>\n",
       "      <td>0.992920</td>\n",
       "      <td>0.992385</td>\n",
       "      <td>0.952671</td>\n",
       "      <td>0.912326</td>\n",
       "      <td>0.962260</td>\n",
       "      <td>0.963030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.149900</td>\n",
       "      <td>0.159980</td>\n",
       "      <td>0.992920</td>\n",
       "      <td>0.992569</td>\n",
       "      <td>0.961103</td>\n",
       "      <td>0.932756</td>\n",
       "      <td>0.968665</td>\n",
       "      <td>0.970637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.125300</td>\n",
       "      <td>0.159863</td>\n",
       "      <td>0.994690</td>\n",
       "      <td>0.994265</td>\n",
       "      <td>0.963270</td>\n",
       "      <td>0.947895</td>\n",
       "      <td>0.970743</td>\n",
       "      <td>0.977263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.104200</td>\n",
       "      <td>0.149660</td>\n",
       "      <td>0.996460</td>\n",
       "      <td>0.996181</td>\n",
       "      <td>0.963187</td>\n",
       "      <td>0.950154</td>\n",
       "      <td>0.971069</td>\n",
       "      <td>0.979305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.083800</td>\n",
       "      <td>0.132744</td>\n",
       "      <td>0.996460</td>\n",
       "      <td>0.996181</td>\n",
       "      <td>0.965990</td>\n",
       "      <td>0.955751</td>\n",
       "      <td>0.973199</td>\n",
       "      <td>0.981357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.078400</td>\n",
       "      <td>0.141871</td>\n",
       "      <td>0.996460</td>\n",
       "      <td>0.996181</td>\n",
       "      <td>0.965593</td>\n",
       "      <td>0.953306</td>\n",
       "      <td>0.972916</td>\n",
       "      <td>0.980460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.135596</td>\n",
       "      <td>0.996460</td>\n",
       "      <td>0.996181</td>\n",
       "      <td>0.966484</td>\n",
       "      <td>0.956953</td>\n",
       "      <td>0.973585</td>\n",
       "      <td>0.981798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.136554</td>\n",
       "      <td>0.996460</td>\n",
       "      <td>0.996181</td>\n",
       "      <td>0.965706</td>\n",
       "      <td>0.956191</td>\n",
       "      <td>0.972984</td>\n",
       "      <td>0.981518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1.0: \n",
      "Classification report for intents: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        29\n",
      "           1       1.00      0.95      0.98        21\n",
      "           2       1.00      1.00      1.00        28\n",
      "           3       1.00      1.00      1.00        20\n",
      "           4       0.98      1.00      0.99        40\n",
      "           5       0.98      1.00      0.99        41\n",
      "           6       1.00      1.00      1.00        36\n",
      "           7       1.00      0.96      0.98        27\n",
      "           8       1.00      1.00      1.00        40\n",
      "           9       0.97      1.00      0.98        28\n",
      "          10       1.00      0.92      0.96        26\n",
      "          11       1.00      1.00      1.00        38\n",
      "          12       0.96      1.00      0.98        27\n",
      "          13       1.00      1.00      1.00        20\n",
      "          14       1.00      1.00      1.00        36\n",
      "          15       1.00      0.97      0.98        32\n",
      "          16       1.00      1.00      1.00        21\n",
      "          17       1.00      1.00      1.00        27\n",
      "          18       1.00      1.00      1.00        28\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       565\n",
      "   macro avg       0.99      0.99      0.99       565\n",
      "weighted avg       0.99      0.99      0.99       565\n",
      " samples avg       0.99      0.99      0.99       565\n",
      "\n",
      "Classification report for tags: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.41      0.56       198\n",
      "           1       0.00      0.00      0.00        26\n",
      "           2       0.00      0.00      0.00        35\n",
      "           3       0.95      0.89      0.92        88\n",
      "           4       1.00      1.00      1.00       565\n",
      "           5       1.00      0.24      0.39        46\n",
      "           6       0.98      0.98      0.98       139\n",
      "           7       0.98      0.90      0.94       113\n",
      "           8       0.90      1.00      0.95       494\n",
      "           9       1.00      0.03      0.06        32\n",
      "          10       0.50      0.01      0.02       115\n",
      "\n",
      "   micro avg       0.95      0.79      0.87      1851\n",
      "   macro avg       0.74      0.50      0.53      1851\n",
      "weighted avg       0.89      0.79      0.80      1851\n",
      " samples avg       0.95      0.83      0.87      1851\n",
      "\n",
      "Epoch 2.0: \n",
      "Classification report for intents: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        29\n",
      "           1       1.00      0.95      0.98        21\n",
      "           2       0.93      1.00      0.97        28\n",
      "           3       1.00      1.00      1.00        20\n",
      "           4       1.00      1.00      1.00        40\n",
      "           5       1.00      1.00      1.00        41\n",
      "           6       1.00      1.00      1.00        36\n",
      "           7       1.00      0.96      0.98        27\n",
      "           8       1.00      1.00      1.00        40\n",
      "           9       0.96      0.96      0.96        28\n",
      "          10       1.00      1.00      1.00        26\n",
      "          11       1.00      1.00      1.00        38\n",
      "          12       1.00      1.00      1.00        27\n",
      "          13       1.00      1.00      1.00        20\n",
      "          14       1.00      1.00      1.00        36\n",
      "          15       1.00      0.97      0.98        32\n",
      "          16       1.00      1.00      1.00        21\n",
      "          17       0.96      1.00      0.98        27\n",
      "          18       1.00      1.00      1.00        28\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       565\n",
      "   macro avg       0.99      0.99      0.99       565\n",
      "weighted avg       0.99      0.99      0.99       565\n",
      " samples avg       0.99      0.99      0.99       565\n",
      "\n",
      "Classification report for tags: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.64      0.77       198\n",
      "           1       1.00      0.19      0.32        26\n",
      "           2       0.00      0.00      0.00        35\n",
      "           3       0.95      0.95      0.95        88\n",
      "           4       1.00      1.00      1.00       565\n",
      "           5       0.88      0.65      0.75        46\n",
      "           6       0.99      0.99      0.99       139\n",
      "           7       0.99      0.98      0.99       113\n",
      "           8       0.93      1.00      0.96       494\n",
      "           9       1.00      0.72      0.84        32\n",
      "          10       0.89      0.41      0.56       115\n",
      "\n",
      "   micro avg       0.97      0.88      0.92      1851\n",
      "   macro avg       0.87      0.68      0.74      1851\n",
      "weighted avg       0.95      0.88      0.90      1851\n",
      " samples avg       0.97      0.90      0.92      1851\n",
      "\n",
      "Epoch 3.0: \n",
      "Classification report for intents: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        29\n",
      "           1       1.00      0.95      0.98        21\n",
      "           2       0.97      1.00      0.98        28\n",
      "           3       1.00      1.00      1.00        20\n",
      "           4       1.00      1.00      1.00        40\n",
      "           5       1.00      1.00      1.00        41\n",
      "           6       1.00      1.00      1.00        36\n",
      "           7       1.00      0.96      0.98        27\n",
      "           8       0.98      1.00      0.99        40\n",
      "           9       1.00      0.96      0.98        28\n",
      "          10       1.00      1.00      1.00        26\n",
      "          11       1.00      1.00      1.00        38\n",
      "          12       1.00      1.00      1.00        27\n",
      "          13       1.00      1.00      1.00        20\n",
      "          14       1.00      1.00      1.00        36\n",
      "          15       1.00      1.00      1.00        32\n",
      "          16       1.00      1.00      1.00        21\n",
      "          17       1.00      0.96      0.98        27\n",
      "          18       0.97      1.00      0.98        28\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       565\n",
      "   macro avg       0.99      0.99      0.99       565\n",
      "weighted avg       0.99      0.99      0.99       565\n",
      " samples avg       0.99      0.99      0.99       565\n",
      "\n",
      "Classification report for tags: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.78      0.85       198\n",
      "           1       1.00      0.65      0.79        26\n",
      "           2       1.00      0.86      0.92        35\n",
      "           3       0.97      0.94      0.95        88\n",
      "           4       1.00      1.00      1.00       565\n",
      "           5       1.00      0.93      0.97        46\n",
      "           6       1.00      0.99      0.99       139\n",
      "           7       1.00      0.98      0.99       113\n",
      "           8       0.95      0.99      0.97       494\n",
      "           9       1.00      0.78      0.88        32\n",
      "          10       1.00      0.57      0.72       115\n",
      "\n",
      "   micro avg       0.98      0.93      0.95      1851\n",
      "   macro avg       0.99      0.86      0.91      1851\n",
      "weighted avg       0.98      0.93      0.95      1851\n",
      " samples avg       0.98      0.94      0.95      1851\n",
      "\n",
      "Epoch 4.0: \n",
      "Classification report for intents: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        29\n",
      "           1       1.00      0.95      0.98        21\n",
      "           2       1.00      1.00      1.00        28\n",
      "           3       1.00      1.00      1.00        20\n",
      "           4       1.00      1.00      1.00        40\n",
      "           5       1.00      1.00      1.00        41\n",
      "           6       1.00      1.00      1.00        36\n",
      "           7       1.00      0.96      0.98        27\n",
      "           8       1.00      1.00      1.00        40\n",
      "           9       0.97      1.00      0.98        28\n",
      "          10       1.00      1.00      1.00        26\n",
      "          11       1.00      0.97      0.99        38\n",
      "          12       1.00      1.00      1.00        27\n",
      "          13       1.00      1.00      1.00        20\n",
      "          14       0.97      1.00      0.99        36\n",
      "          15       1.00      1.00      1.00        32\n",
      "          16       1.00      1.00      1.00        21\n",
      "          17       1.00      0.96      0.98        27\n",
      "          18       0.97      1.00      0.98        28\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       565\n",
      "   macro avg       0.99      0.99      0.99       565\n",
      "weighted avg       0.99      0.99      0.99       565\n",
      " samples avg       0.99      0.99      0.99       565\n",
      "\n",
      "Classification report for tags: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.74      0.84       198\n",
      "           1       1.00      0.73      0.84        26\n",
      "           2       1.00      0.91      0.96        35\n",
      "           3       0.97      0.98      0.97        88\n",
      "           4       1.00      1.00      1.00       565\n",
      "           5       1.00      0.96      0.98        46\n",
      "           6       1.00      0.99      1.00       139\n",
      "           7       1.00      0.98      0.99       113\n",
      "           8       0.96      0.99      0.97       494\n",
      "           9       1.00      0.75      0.86        32\n",
      "          10       1.00      0.75      0.86       115\n",
      "\n",
      "   micro avg       0.98      0.94      0.96      1851\n",
      "   macro avg       0.99      0.89      0.93      1851\n",
      "weighted avg       0.98      0.94      0.96      1851\n",
      " samples avg       0.98      0.95      0.96      1851\n",
      "\n",
      "Epoch 5.0: \n",
      "Classification report for intents: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        29\n",
      "           1       1.00      0.95      0.98        21\n",
      "           2       1.00      1.00      1.00        28\n",
      "           3       1.00      1.00      1.00        20\n",
      "           4       1.00      1.00      1.00        40\n",
      "           5       1.00      1.00      1.00        41\n",
      "           6       1.00      1.00      1.00        36\n",
      "           7       1.00      0.96      0.98        27\n",
      "           8       0.98      1.00      0.99        40\n",
      "           9       1.00      1.00      1.00        28\n",
      "          10       1.00      1.00      1.00        26\n",
      "          11       1.00      1.00      1.00        38\n",
      "          12       1.00      1.00      1.00        27\n",
      "          13       1.00      1.00      1.00        20\n",
      "          14       1.00      1.00      1.00        36\n",
      "          15       1.00      1.00      1.00        32\n",
      "          16       1.00      1.00      1.00        21\n",
      "          17       1.00      0.96      0.98        27\n",
      "          18       0.97      1.00      0.98        28\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       565\n",
      "   macro avg       1.00      0.99      0.99       565\n",
      "weighted avg       0.99      0.99      0.99       565\n",
      " samples avg       0.99      0.99      0.99       565\n",
      "\n",
      "Classification report for tags: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84       198\n",
      "           1       1.00      0.96      0.98        26\n",
      "           2       1.00      1.00      1.00        35\n",
      "           3       0.98      0.99      0.98        88\n",
      "           4       1.00      1.00      1.00       565\n",
      "           5       1.00      0.96      0.98        46\n",
      "           6       1.00      0.99      1.00       139\n",
      "           7       1.00      0.98      0.99       113\n",
      "           8       0.95      0.99      0.97       494\n",
      "           9       1.00      0.75      0.86        32\n",
      "          10       1.00      0.71      0.83       115\n",
      "\n",
      "   micro avg       0.99      0.94      0.96      1851\n",
      "   macro avg       0.99      0.91      0.95      1851\n",
      "weighted avg       0.99      0.94      0.96      1851\n",
      " samples avg       0.99      0.95      0.96      1851\n",
      "\n",
      "Epoch 6.0: \n",
      "Classification report for intents: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        29\n",
      "           1       1.00      0.95      0.98        21\n",
      "           2       1.00      1.00      1.00        28\n",
      "           3       1.00      1.00      1.00        20\n",
      "           4       1.00      1.00      1.00        40\n",
      "           5       1.00      1.00      1.00        41\n",
      "           6       1.00      1.00      1.00        36\n",
      "           7       1.00      0.96      0.98        27\n",
      "           8       0.98      1.00      0.99        40\n",
      "           9       1.00      1.00      1.00        28\n",
      "          10       1.00      1.00      1.00        26\n",
      "          11       1.00      1.00      1.00        38\n",
      "          12       1.00      1.00      1.00        27\n",
      "          13       1.00      1.00      1.00        20\n",
      "          14       1.00      1.00      1.00        36\n",
      "          15       1.00      1.00      1.00        32\n",
      "          16       1.00      1.00      1.00        21\n",
      "          17       1.00      1.00      1.00        27\n",
      "          18       1.00      1.00      1.00        28\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       565\n",
      "   macro avg       1.00      1.00      1.00       565\n",
      "weighted avg       1.00      1.00      1.00       565\n",
      " samples avg       1.00      1.00      1.00       565\n",
      "\n",
      "Classification report for tags: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.75      0.83       198\n",
      "           1       1.00      0.96      0.98        26\n",
      "           2       1.00      1.00      1.00        35\n",
      "           3       0.99      0.95      0.97        88\n",
      "           4       1.00      1.00      1.00       565\n",
      "           5       1.00      0.98      0.99        46\n",
      "           6       1.00      1.00      1.00       139\n",
      "           7       1.00      0.98      0.99       113\n",
      "           8       0.96      1.00      0.98       494\n",
      "           9       0.96      0.81      0.88        32\n",
      "          10       1.00      0.71      0.83       115\n",
      "\n",
      "   micro avg       0.98      0.95      0.96      1851\n",
      "   macro avg       0.98      0.92      0.95      1851\n",
      "weighted avg       0.98      0.95      0.96      1851\n",
      " samples avg       0.98      0.95      0.96      1851\n",
      "\n",
      "Epoch 7.0: \n",
      "Classification report for intents: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        29\n",
      "           1       1.00      0.95      0.98        21\n",
      "           2       1.00      1.00      1.00        28\n",
      "           3       1.00      1.00      1.00        20\n",
      "           4       1.00      1.00      1.00        40\n",
      "           5       1.00      1.00      1.00        41\n",
      "           6       1.00      1.00      1.00        36\n",
      "           7       1.00      0.96      0.98        27\n",
      "           8       0.98      1.00      0.99        40\n",
      "           9       1.00      1.00      1.00        28\n",
      "          10       1.00      1.00      1.00        26\n",
      "          11       1.00      1.00      1.00        38\n",
      "          12       1.00      1.00      1.00        27\n",
      "          13       1.00      1.00      1.00        20\n",
      "          14       1.00      1.00      1.00        36\n",
      "          15       1.00      1.00      1.00        32\n",
      "          16       1.00      1.00      1.00        21\n",
      "          17       1.00      1.00      1.00        27\n",
      "          18       1.00      1.00      1.00        28\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       565\n",
      "   macro avg       1.00      1.00      1.00       565\n",
      "weighted avg       1.00      1.00      1.00       565\n",
      " samples avg       1.00      1.00      1.00       565\n",
      "\n",
      "Classification report for tags: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.77      0.84       198\n",
      "           1       1.00      0.96      0.98        26\n",
      "           2       1.00      1.00      1.00        35\n",
      "           3       0.98      0.98      0.98        88\n",
      "           4       1.00      1.00      1.00       565\n",
      "           5       1.00      0.98      0.99        46\n",
      "           6       1.00      0.99      1.00       139\n",
      "           7       1.00      0.99      1.00       113\n",
      "           8       0.96      0.99      0.98       494\n",
      "           9       1.00      0.81      0.90        32\n",
      "          10       1.00      0.76      0.86       115\n",
      "\n",
      "   micro avg       0.98      0.95      0.97      1851\n",
      "   macro avg       0.99      0.93      0.96      1851\n",
      "weighted avg       0.98      0.95      0.96      1851\n",
      " samples avg       0.98      0.96      0.96      1851\n",
      "\n",
      "Epoch 8.0: \n",
      "Classification report for intents: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        29\n",
      "           1       1.00      0.95      0.98        21\n",
      "           2       1.00      1.00      1.00        28\n",
      "           3       1.00      1.00      1.00        20\n",
      "           4       1.00      1.00      1.00        40\n",
      "           5       1.00      1.00      1.00        41\n",
      "           6       1.00      1.00      1.00        36\n",
      "           7       1.00      0.96      0.98        27\n",
      "           8       0.98      1.00      0.99        40\n",
      "           9       1.00      1.00      1.00        28\n",
      "          10       1.00      1.00      1.00        26\n",
      "          11       1.00      1.00      1.00        38\n",
      "          12       1.00      1.00      1.00        27\n",
      "          13       1.00      1.00      1.00        20\n",
      "          14       1.00      1.00      1.00        36\n",
      "          15       1.00      1.00      1.00        32\n",
      "          16       1.00      1.00      1.00        21\n",
      "          17       1.00      1.00      1.00        27\n",
      "          18       1.00      1.00      1.00        28\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       565\n",
      "   macro avg       1.00      1.00      1.00       565\n",
      "weighted avg       1.00      1.00      1.00       565\n",
      " samples avg       1.00      1.00      1.00       565\n",
      "\n",
      "Classification report for tags: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.75      0.84       198\n",
      "           1       1.00      0.96      0.98        26\n",
      "           2       1.00      1.00      1.00        35\n",
      "           3       0.98      0.98      0.98        88\n",
      "           4       1.00      1.00      1.00       565\n",
      "           5       1.00      0.93      0.97        46\n",
      "           6       1.00      0.99      1.00       139\n",
      "           7       1.00      0.98      0.99       113\n",
      "           8       0.96      0.99      0.98       494\n",
      "           9       1.00      0.81      0.90        32\n",
      "          10       1.00      0.76      0.86       115\n",
      "\n",
      "   micro avg       0.98      0.95      0.97      1851\n",
      "   macro avg       0.99      0.92      0.95      1851\n",
      "weighted avg       0.98      0.95      0.96      1851\n",
      " samples avg       0.98      0.95      0.96      1851\n",
      "\n",
      "Epoch 9.0: \n",
      "Classification report for intents: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        29\n",
      "           1       1.00      0.95      0.98        21\n",
      "           2       1.00      1.00      1.00        28\n",
      "           3       1.00      1.00      1.00        20\n",
      "           4       1.00      1.00      1.00        40\n",
      "           5       1.00      1.00      1.00        41\n",
      "           6       1.00      1.00      1.00        36\n",
      "           7       1.00      0.96      0.98        27\n",
      "           8       0.98      1.00      0.99        40\n",
      "           9       1.00      1.00      1.00        28\n",
      "          10       1.00      1.00      1.00        26\n",
      "          11       1.00      1.00      1.00        38\n",
      "          12       1.00      1.00      1.00        27\n",
      "          13       1.00      1.00      1.00        20\n",
      "          14       1.00      1.00      1.00        36\n",
      "          15       1.00      1.00      1.00        32\n",
      "          16       1.00      1.00      1.00        21\n",
      "          17       1.00      1.00      1.00        27\n",
      "          18       1.00      1.00      1.00        28\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       565\n",
      "   macro avg       1.00      1.00      1.00       565\n",
      "weighted avg       1.00      1.00      1.00       565\n",
      " samples avg       1.00      1.00      1.00       565\n",
      "\n",
      "Classification report for tags: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.75      0.84       198\n",
      "           1       1.00      0.96      0.98        26\n",
      "           2       1.00      1.00      1.00        35\n",
      "           3       0.98      0.98      0.98        88\n",
      "           4       1.00      1.00      1.00       565\n",
      "           5       1.00      1.00      1.00        46\n",
      "           6       1.00      0.99      1.00       139\n",
      "           7       1.00      0.98      0.99       113\n",
      "           8       0.96      0.99      0.98       494\n",
      "           9       1.00      0.81      0.90        32\n",
      "          10       1.00      0.77      0.87       115\n",
      "\n",
      "   micro avg       0.98      0.95      0.97      1851\n",
      "   macro avg       0.99      0.93      0.96      1851\n",
      "weighted avg       0.98      0.95      0.96      1851\n",
      " samples avg       0.98      0.96      0.96      1851\n",
      "\n",
      "Epoch 10.0: \n",
      "Classification report for intents: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        29\n",
      "           1       1.00      0.95      0.98        21\n",
      "           2       1.00      1.00      1.00        28\n",
      "           3       1.00      1.00      1.00        20\n",
      "           4       1.00      1.00      1.00        40\n",
      "           5       1.00      1.00      1.00        41\n",
      "           6       1.00      1.00      1.00        36\n",
      "           7       1.00      0.96      0.98        27\n",
      "           8       0.98      1.00      0.99        40\n",
      "           9       1.00      1.00      1.00        28\n",
      "          10       1.00      1.00      1.00        26\n",
      "          11       1.00      1.00      1.00        38\n",
      "          12       1.00      1.00      1.00        27\n",
      "          13       1.00      1.00      1.00        20\n",
      "          14       1.00      1.00      1.00        36\n",
      "          15       1.00      1.00      1.00        32\n",
      "          16       1.00      1.00      1.00        21\n",
      "          17       1.00      1.00      1.00        27\n",
      "          18       1.00      1.00      1.00        28\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       565\n",
      "   macro avg       1.00      1.00      1.00       565\n",
      "weighted avg       1.00      1.00      1.00       565\n",
      " samples avg       1.00      1.00      1.00       565\n",
      "\n",
      "Classification report for tags: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.76      0.83       198\n",
      "           1       1.00      0.96      0.98        26\n",
      "           2       1.00      1.00      1.00        35\n",
      "           3       0.98      0.98      0.98        88\n",
      "           4       1.00      1.00      1.00       565\n",
      "           5       1.00      1.00      1.00        46\n",
      "           6       1.00      0.99      1.00       139\n",
      "           7       1.00      0.98      0.99       113\n",
      "           8       0.96      0.99      0.98       494\n",
      "           9       1.00      0.81      0.90        32\n",
      "          10       1.00      0.77      0.87       115\n",
      "\n",
      "   micro avg       0.98      0.95      0.97      1851\n",
      "   macro avg       0.99      0.93      0.96      1851\n",
      "weighted avg       0.98      0.95      0.96      1851\n",
      " samples avg       0.98      0.96      0.96      1851\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11450, training_loss=0.18457267278146536, metrics={'train_runtime': 969.4901, 'train_samples_per_second': 47.241, 'train_steps_per_second': 11.81, 'total_flos': 1517509089792000.0, 'train_loss': 0.18457267278146536, 'epoch': 10.0})"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fa723d2d-8c02-4c43-b4c3-fa6ba9fea237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='142' max='142' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [142/142 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for intents: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        29\n",
      "           1       1.00      0.95      0.98        21\n",
      "           2       1.00      1.00      1.00        28\n",
      "           3       1.00      1.00      1.00        20\n",
      "           4       1.00      1.00      1.00        40\n",
      "           5       1.00      1.00      1.00        41\n",
      "           6       1.00      1.00      1.00        36\n",
      "           7       1.00      0.96      0.98        27\n",
      "           8       0.98      1.00      0.99        40\n",
      "           9       1.00      1.00      1.00        28\n",
      "          10       1.00      1.00      1.00        26\n",
      "          11       1.00      1.00      1.00        38\n",
      "          12       1.00      1.00      1.00        27\n",
      "          13       1.00      1.00      1.00        20\n",
      "          14       1.00      1.00      1.00        36\n",
      "          15       1.00      1.00      1.00        32\n",
      "          16       1.00      1.00      1.00        21\n",
      "          17       1.00      1.00      1.00        27\n",
      "          18       1.00      1.00      1.00        28\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       565\n",
      "   macro avg       1.00      1.00      1.00       565\n",
      "weighted avg       1.00      1.00      1.00       565\n",
      " samples avg       1.00      1.00      1.00       565\n",
      "\n",
      "Classification report for tags: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.75      0.84       198\n",
      "           1       1.00      0.96      0.98        26\n",
      "           2       1.00      1.00      1.00        35\n",
      "           3       0.98      0.98      0.98        88\n",
      "           4       1.00      1.00      1.00       565\n",
      "           5       1.00      1.00      1.00        46\n",
      "           6       1.00      0.99      1.00       139\n",
      "           7       1.00      0.98      0.99       113\n",
      "           8       0.96      0.99      0.98       494\n",
      "           9       1.00      0.81      0.90        32\n",
      "          10       1.00      0.77      0.87       115\n",
      "\n",
      "   micro avg       0.98      0.95      0.97      1851\n",
      "   macro avg       0.99      0.93      0.96      1851\n",
      "weighted avg       0.98      0.95      0.96      1851\n",
      " samples avg       0.98      0.96      0.96      1851\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.1355958878993988,\n",
       " 'eval_f1_micro_for_intents': 0.9964601769911504,\n",
       " 'eval_f1_macro_for_intents': 0.9961814210533968,\n",
       " 'eval_f1_micro_for_tags': 0.9664835164835165,\n",
       " 'eval_f1_macro_for_tags': 0.956952796160882,\n",
       " 'eval_f1_micro': 0.9735849056603774,\n",
       " 'eval_f1_macro': 0.9817975919261415,\n",
       " 'eval_runtime': 2.3879,\n",
       " 'eval_samples_per_second': 236.612,\n",
       " 'eval_steps_per_second': 59.467,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "38516101-e701-4c84-8287-0dbd39ad1707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for future use\n",
    "model.save_pretrained('./models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc75a4c1-2e06-46e0-88f0-105cc2a262f6",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61983f96-d9c8-4bb3-b7e0-e5ee57fca7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81d1eb73-38d5-4e82-a669-4559b49f7304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Load the custom pretrained model\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "grandparent_directory = os.path.dirname(parent_directory)\n",
    "\n",
    "#navigate to model directory\n",
    "model_path = os.path.join(grandparent_directory, 'models')\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd4c61a3-2e11-4112-8fb6-f8bc067decff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35ccb950-e5f2-4da1-8620-75e8f64ab021",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts =  \"i have bought the same item twice cancel order 00123842\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71bf52bc-93a3-4d93-97f1-8959609d7f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the text\n",
    "encoded_input = tokenizer(input_texts,\n",
    "                          truncation=True,\n",
    "                          padding=\"max_length\",\n",
    "                          max_length=128,\n",
    "                          return_tensors='pt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e0f0d2d-98ce-4a12-b765-849af0e94e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the model to predict under the format of logits of 30 classes\n",
    "logits = model(**encoded_input).logits.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42e60cd4-f59b-453c-9304-97a89e613fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the result\n",
    "preds = get_preds_from_logits(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "65dc438f-8a88-426b-b0b6-edcb2970cfa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f6c53a-61a6-45e8-bb27-a5c2479e67d5",
   "metadata": {},
   "source": [
    "## TRANSLATING OUTPUTS FROM OUTPUT LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "65d88329-6d64-4d32-bbd4-6c25faa6f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABEL DICTIONARY\n",
    "\n",
    "intents_map = {\n",
    "    0: 'cancel_order',\n",
    "    1: 'change_order',\n",
    "    2: 'change_shipping_address',\n",
    "    3: 'check_payment_methods',\n",
    "    4: 'check_refund_policy',\n",
    "    5: 'contact_customer_service',\n",
    "    6: 'contact_human_agent',\n",
    "    7: 'create_account',\n",
    "    8: 'delete_account',\n",
    "    9: 'edit_account',\n",
    "   10: 'get_refund',\n",
    "   11: 'payment_issue',\n",
    "   12: 'place_order',\n",
    "   13: 'recover_password',\n",
    "   14: 'registration_problems',\n",
    "   15: 'set_up_shipping_address',\n",
    "   16: 'switch_account',\n",
    "   17: 'track_order',\n",
    "   18: 'track_refund'\n",
    "}\n",
    "\n",
    "tags_labels = np.array(['Q', 'P', 'W', 'K', 'B', 'C', 'I', 'M', 'L', 'E', 'Z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "893c64a7-9549-4bae-8a0b-5a373d818d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "intents_array = preds[0][:19]\n",
    "tags_array = preds[0][19:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "412f15d7-4856-492b-9449-8fd427d8b291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "55d682ec-845d-49f4-9f31-cee4ec793c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74347ac6-eed1-4d15-a893-e88b711f06c1",
   "metadata": {},
   "source": [
    "### Intent Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b0ae37a2-fc19-4220-922c-a9bf4f0a413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent = intents_map[intents_array.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "285ff9e7-3b88-47e7-be03-826f6245392d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cancel_order'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ce9f05-945b-4259-b040-7b3e46bee787",
   "metadata": {},
   "source": [
    "### Language Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14f826fd-2158-4f2e-9f23-e466577031ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tag = \"\"\n",
    "\n",
    "for i in np.where(tags_array == 1)[0]:\n",
    "  output_tag += tags_labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5d330733-e9ca-404f-a96e-6749644d7583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BCL'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
